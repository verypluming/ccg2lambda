{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 {1: 1} 1.07127522587\n",
      "0.000278255940221 {1: 1} 1.07127709514\n",
      "0.000774263682681 {1: 1} 1.07127535164\n",
      "0.00215443469003 {1: 1} 1.07126985291\n",
      "0.00599484250319 {1: 1} 1.07127789196\n",
      "0.016681005372 {1: 1} 1.07126869865\n",
      "0.0464158883361 {1: 1} 1.07127232944\n",
      "0.129154966501 {1: 1} 1.07126974895\n",
      "0.35938136638 {1: 1} 1.07127024619\n",
      "1.0 {1: 1} 1.07126981779\n",
      "0.00599484250319 {1: 1} 1.07127789196\n",
      "accuracy (traditional): 0.703175715749\n",
      "accuracy (non-traditional): 0.296824284251\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2 features per sample; expecting 14",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-72098cd30852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m XX, YY = np.meshgrid(np.linspace(X[:,0].min()-offset,X[:,0].max()+offset,100),\n\u001b[1;32m    110\u001b[0m                          np.linspace(X[:,1].min()-offset,X[:,1].max()+offset,100))\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yanakahitomi/.pyenv/versions/3.5.0/envs/ccg2lambda/lib/python3.5/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 317\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 2 features per sample; expecting 14"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "\n",
    "class PUClassifier(object):\n",
    "    def __init__(self, trad_clf=None, n_folds=2):\n",
    "        self.trad_clf = trad_clf\n",
    "        self.n_folds = n_folds\n",
    "\n",
    "    def fit(self, X, s):\n",
    "        if self.trad_clf is None:\n",
    "            self.trad_clf = GridSearchCV(SGDClassifier(loss=\"log\", penalty=\"l2\"), param_grid={\"alpha\": np.logspace(-4, 0, 10)})\n",
    "\n",
    "        c = np.zeros(self.n_folds)\n",
    "        for i, (itr, ite) in enumerate(StratifiedKFold(s, n_folds=self.n_folds, shuffle=True)):\n",
    "            self.trad_clf.fit(X[itr], s[itr])\n",
    "            c[i] = self.trad_clf.predict_proba(X[ite][s[ite]==1])[:,1].mean()\n",
    "        self.c = c.mean()\n",
    "        return self\n",
    "\n",
    "    def sample(self, X, s):\n",
    "        if not hasattr(self, \"c\"):\n",
    "            self.fit(X, s)\n",
    "        X_positive = X[s==1]\n",
    "        X_unlabeled = X[s==0]\n",
    "        n_positive = X_positive.shape[0]\n",
    "        n_unlabeled = X_unlabeled.shape[0]\n",
    "\n",
    "        X_train = np.r_[X_positive, X_unlabeled, X_unlabeled]\n",
    "        y_train = np.concatenate([np.repeat(1, n_positive), np.repeat(1, n_unlabeled), np.repeat(0, n_unlabeled)])\n",
    "\n",
    "        self.trad_clf.fit(X, s)\n",
    "        p_unlabeled = self.trad_clf.predict_proba(X_unlabeled)[:,1]\n",
    "        w_positive = ((1 - self.c) / self.c) * (p_unlabeled / (1 - p_unlabeled))\n",
    "        w_negative = 1 - w_positive\n",
    "        sample_weight = np.concatenate([np.repeat(1.0, n_positive), w_positive, w_negative])\n",
    "        return X_train, y_train, sample_weight\n",
    "\n",
    "with open('phrase_classifier_23fd213/features.pickle', 'rb') as in_f:\n",
    "    load_target = np.load(in_f)\n",
    "    load_source = np.load(in_f)\n",
    "    load_source_phrase = np.load(in_f)\n",
    "\n",
    "#positive\n",
    "#np.where(load_target==1)\n",
    "#negative\n",
    "#np.where(load_target==0)\n",
    "\n",
    "np.random.seed(0)\n",
    "#n_positive = 100\n",
    "#n_negative = 500\n",
    "n_positive = len(load_target[np.where(load_target==1)])\n",
    "n_negative = len(load_target[np.where(load_target==0)])\n",
    "n = n_positive + n_negative\n",
    "X = np.r_[load_source[np.where(load_target==1)], load_source[np.where(load_target==0)]]\n",
    "y = np.concatenate([np.repeat(1, n_positive), np.repeat(0, n_negative)])\n",
    "mu1 = [0,0]\n",
    "mu2 = [2,2]\n",
    "Sigma1 = 0.1 * np.identity(2)\n",
    "Sigma2 = 0.5 * np.identity(2)\n",
    "#X = np.r_[np.random.multivariate_normal(mu1, Sigma1, n_positive),\n",
    "#        np.random.multivariate_normal(mu2, Sigma2, n_negative)]\n",
    "#y = np.concatenate([np.repeat(1, n_positive), np.repeat(0, n_negative)])\n",
    "n_unlabeled = int(n_positive * 0.7)\n",
    "s = y.copy()\n",
    "s[:n_unlabeled] = 0\n",
    "\n",
    "pu = PUClassifier(n_folds=5)\n",
    "X_train, y_train, sample_weight = pu.sample(X, s)\n",
    "alphas = np.logspace(-4, 0, 10)\n",
    "class_weights = [{1:1}]\n",
    "n_folds = 3\n",
    "best_score = -np.inf\n",
    "best_alpha = None\n",
    "best_class_weight = None\n",
    "for alpha, class_weight in itertools.product(alphas, class_weights):\n",
    "    scores = np.zeros(n_folds)\n",
    "    for i, (itr, ite) in enumerate(StratifiedKFold(y_train, n_folds=n_folds, shuffle=True)):\n",
    "        clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", alpha=alpha, class_weight=class_weight).fit(X_train[itr], y_train[itr], sample_weight=sample_weight[itr])\n",
    "        ypred = clf.predict(X_train[ite])\n",
    "        scores[i] = metrics.accuracy_score(y_train[ite], ypred, sample_weight=sample_weight[ite])\n",
    "    this_score = scores.mean()\n",
    "    print(alpha, class_weight, this_score)\n",
    "    if this_score > best_score:\n",
    "        best_score = this_score\n",
    "        best_alpha = alpha\n",
    "        best_class_weight = class_weight\n",
    "\n",
    "print(best_alpha, best_class_weight, best_score)\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", alpha=best_alpha, class_weight=best_class_weight).fit(X_train, y_train, sample_weight=sample_weight)\n",
    "\n",
    "ypred = clf.predict(X[s==0])\n",
    "#ypred = pu.trad_clf.predict_proba(X[s==0])[:,1]>=0.5*pu.c # <- this can also be used. \n",
    "trad_ypred = pu.trad_clf.predict(X[s==0])\n",
    "accuracy = metrics.accuracy_score(y[s==0], ypred)\n",
    "trad_accuracy = metrics.accuracy_score(y[s==0], trad_ypred)\n",
    "print(\"accuracy (traditional):\", trad_accuracy)\n",
    "print(\"accuracy (non-traditional):\", accuracy)\n",
    "\n",
    "# plot\n",
    "ypred = clf.predict(X)\n",
    "trad_ypred = pu.trad_clf.predict(X)\n",
    "offset = 1.0\n",
    "XX, YY = np.meshgrid(np.linspace(X[:,0].min()-offset,X[:,0].max()+offset,100),\n",
    "                         np.linspace(X[:,1].min()-offset,X[:,1].max()+offset,100))\n",
    "Z = clf.decision_function(np.c_[XX.ravel(),YY.ravel()])\n",
    "Z = Z.reshape(XX.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "colors = [\"r\", \"b\"]\n",
    "plot_colors = [colors[yy] for yy in y==1]\n",
    "plt.scatter(X[:,0], X[:,1], s=50, color=plot_colors)\n",
    "plt.title(\"true\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "colors = [\"gray\", \"b\"]\n",
    "plot_colors = [colors[ss] for ss in s]\n",
    "plt.scatter(X[:,0], X[:,1], s=50, color=plot_colors)\n",
    "plt.title(\"positive and unlabeled data\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "colors = [\"r\", \"b\"]\n",
    "plot_colors = [colors[yy] for yy in trad_ypred]\n",
    "plt.scatter(X[:,0], X[:,1], s=50, color=plot_colors)\n",
    "plt.title(\"traditional (accuracy={})\".format(trad_accuracy))\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "colors = [\"r\", \"b\"]\n",
    "plot_colors = [colors[yy] for yy in ypred]\n",
    "plt.contour(XX, YY, Z, levels=[0.0], colors=\"green\")\n",
    "plt.scatter(X[:,0], X[:,1], s=50, color=plot_colors)\n",
    "plt.title(\"non-traditional (accuracy={})\".format(accuracy))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#plt.savefig(\"pusampler_demo.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39324"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104533, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_2 = np.r_[load_source[np.where(load_target==1)], load_source[np.where(load_target==0)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.r_[np.random.multivariate_normal(mu1, Sigma1, n_positive),\n",
    "        np.random.multivariate_normal(mu2, Sigma2, n_negative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104533, 14)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
